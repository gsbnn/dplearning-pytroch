# ResNet  

## 深层网络遇到的问题  
- 梯度消失：靠近底层的网络参数得不到有效更新，收敛速度慢。   
- 网络退化：传统深度网络在层数增加时，训练误差反而上升（非过拟合），称为“网络退化”。   

## ResNet  
![残差块](picture\ResNet_block.jpg)  

优点：  
- 简化优化目标：残差映射$f(\bold x) − \bold x$往往更容易优化。假设输入$\bold x$已经接近理想输出$f(\bold x)$，则$f(\bold x) − \bold x$只需学习一个微小的调整量（接近零），这比直接学习完整的$f(\bold x)$（左图）更容易。  

- 跳跃连接——梯度传播的“高速公路”：即使常规路径的梯度衰减到接近零，跳跃路径仍能保持稳定的梯度信号，确保浅层权重有效更新。  

- 缓解网络退化：恒等映射$f(\bold x) = \bold x$的具有保底能力，即使新增的层对特征提取无帮助，网络性能也不会低于其浅层版本。 

- 与批量规范化共同使用进一步缓解梯度异常，加速收敛。