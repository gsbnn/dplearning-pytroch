{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8284271247461903\n",
      "torch.float32\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7]])\n",
      "tensor(19)\n",
      "[2, 4, 6, 8]\n",
      "tensor([[ 0],\n",
      "        [ 1],\n",
      "        [ 2],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10],\n",
      "        [11],\n",
      "        [12],\n",
      "        [13],\n",
      "        [14],\n",
      "        [15],\n",
      "        [16],\n",
      "        [17],\n",
      "        [18],\n",
      "        [19]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
      "        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n",
      "        [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27],\n",
      "        [28, 29, 30, 31],\n",
      "        [32, 33, 34, 35],\n",
      "        [36, 37, 38, 39],\n",
      "        [40, 41, 42, 43],\n",
      "        [44, 45, 46, 47],\n",
      "        [48, 49, 50, 51],\n",
      "        [52, 53, 54, 55],\n",
      "        [56, 57, 58, 59],\n",
      "        [60, 61, 62, 63],\n",
      "        [64, 65, 66, 67],\n",
      "        [68, 69, 70, 71]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
      "        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n",
      "        [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
      "        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n",
      "        [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]])\n",
      "tensor([[ 0,  4,  8, 12, 16],\n",
      "        [ 1,  5,  9, 13, 17],\n",
      "        [ 2,  6, 10, 14, 18],\n",
      "        [ 3,  7, 11, 15, 19]])\n",
      "tensor([[ 0],\n",
      "        [ 1],\n",
      "        [ 2],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10],\n",
      "        [11],\n",
      "        [12],\n",
      "        [13],\n",
      "        [14],\n",
      "        [15],\n",
      "        [16],\n",
      "        [17],\n",
      "        [18],\n",
      "        [19]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "x = np.array([[1,1], [2,2], [3,3], [4,4], [5,5]])\n",
    "y = np.array([[2,2], [3,3], [4,4]])\n",
    "distance, path = fastdtw(x, y, dist=euclidean)\n",
    "print(distance)\n",
    "n_nodes = 10\n",
    "upper_tri = torch.randint(0, 2, (n_nodes, n_nodes)) # 随机生成[0, 2)之间的整数\n",
    "upper_tri = torch.triu(upper_tri, diagonal=1) # 将矩阵主对角及主对角以下元素设置为0\n",
    "adj_matrix = upper_tri + upper_tri.t() + torch.eye(n_nodes)# 保证邻接矩阵对称\n",
    "print(adj_matrix.dtype)\n",
    "\n",
    "n = torch.arange(0, 20).reshape(10, 2)\n",
    "m = torch.arange(0, 20).reshape(20, 1)\n",
    "index = [0, 1, 2, 3]\n",
    "print(n[index])\n",
    "print(n.reshape(-1)[-1])\n",
    "a = [i for i in range(2, 10, 2)]\n",
    "print(a)\n",
    "print(n.reshape(m.shape))\n",
    "b = torch.arange(0, 72).reshape(6, 12) # time 6, value 4, batch 3\n",
    "print(b)\n",
    "print(b.reshape(-1, 4))\n",
    "c = torch.cat(b.split(3, dim=0), dim=1)\n",
    "print(torch.cat(c.split(12, dim=1), dim=0))\n",
    "d = b.reshape(-1)\n",
    "print(d)\n",
    "print(d.reshape(b.shape))\n",
    "e = torch.arange(0, 20)\n",
    "f = torch.stack(e.split(4, dim=0), dim=1)\n",
    "print(f)\n",
    "print(torch.cat(f.split(1, dim=1), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4., 6., 5., 8., 7., 8., 6., 7., 6., 7.]),\n",
       " tensor([0.5000, 0.4082, 0.4472, 0.3536, 0.3780, 0.3536, 0.4082, 0.3780, 0.4082,\n",
       "         0.3780]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree = torch.sum(adj_matrix, dim=1)\n",
    "degree_inv_sqrt = degree.pow(-0.5)\n",
    "degree, degree_inv_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_norm = adj_matrix * degree_inv_sqrt.reshape(-1, 1)\n",
    "A_norm = A_norm * degree_inv_sqrt\n",
    "\n",
    "adj_norm = adj_matrix * degree_inv_sqrt[:, None] # degree_inv_sqrt[:, None]调整了度矩阵形状\n",
    "adj_norm = adj_norm * degree_inv_sqrt[None, :]\n",
    "A_norm == adj_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3347,  0.4799, -0.8790,  ..., -0.2809,  1.5421, -0.3082],\n",
       "         [-0.0151, -0.2540,  0.8244,  ..., -0.1754,  0.7925,  0.1204],\n",
       "         [ 0.5819, -0.1050,  0.6613,  ...,  0.2452,  0.0655, -0.8171],\n",
       "         [-0.4976,  0.7946,  0.0657,  ...,  0.3853, -0.5544, -0.1056]],\n",
       "\n",
       "        [[ 0.0426,  0.4874,  0.8210,  ...,  0.9566, -0.6089, -0.0787],\n",
       "         [-0.2884,  0.6280, -0.0028,  ...,  0.1571, -0.5574,  1.1035],\n",
       "         [ 0.6859, -0.5241,  0.2817,  ...,  0.2293, -0.5864,  0.1197],\n",
       "         [-0.1644,  0.2097, -0.4034,  ...,  1.1664, -0.3955,  0.4370]],\n",
       "\n",
       "        [[-0.1782, -0.0874,  0.5106,  ...,  0.6927,  0.0215, -1.3095],\n",
       "         [-1.1741,  1.1325,  0.0699,  ..., -1.6634,  0.5199,  0.0522],\n",
       "         [ 0.2421, -0.1489, -0.5400,  ...,  1.9069, -0.6936, -0.1559],\n",
       "         [ 0.2902, -0.7433,  0.6532,  ...,  0.6871, -0.9531, -0.1235]],\n",
       "\n",
       "        [[ 0.3663,  0.4436, -0.0897,  ..., -1.5657,  1.8553,  0.2667],\n",
       "         [-0.5762,  0.1992, -0.1589,  ...,  2.0778, -1.0215,  1.2231],\n",
       "         [-0.0198, -0.2207,  1.5419,  ...,  1.3412, -0.9325,  0.6596],\n",
       "         [ 0.6751, -1.6875, -0.6909,  ..., -0.8942,  1.0982,  0.5530]],\n",
       "\n",
       "        [[-1.2060,  1.0094,  0.7430,  ..., -1.5392,  1.3178, -0.8458],\n",
       "         [ 0.7092, -0.5124,  0.0356,  ..., -1.5251,  0.9058, -1.2159],\n",
       "         [-0.3478,  0.9345,  1.0923,  ...,  0.2006, -1.0497,  1.4871],\n",
       "         [-0.8718,  0.3543,  0.5982,  ..., -0.8765,  1.0053, -0.7657]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((5, 4, 10, 5), dtype=torch.float32)\n",
    "w = torch.randn((5, 8), dtype=torch.float32)\n",
    "y = torch.matmul(A_norm, x)\n",
    "y = torch.matmul(y, w)\n",
    "y = y.reshape(5, 4, -1)\n",
    "y.shape\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3347,  0.4799, -0.8790,  ..., -0.2809,  1.5421, -0.3082],\n",
       "         [-0.0151, -0.2540,  0.8244,  ..., -0.1754,  0.7925,  0.1204],\n",
       "         [ 0.5819, -0.1050,  0.6613,  ...,  0.2452,  0.0655, -0.8171],\n",
       "         [-0.4976,  0.7946,  0.0657,  ...,  0.3853, -0.5544, -0.1056]],\n",
       "\n",
       "        [[ 0.0426,  0.4874,  0.8210,  ...,  0.9566, -0.6089, -0.0787],\n",
       "         [-0.2884,  0.6280, -0.0028,  ...,  0.1571, -0.5574,  1.1035],\n",
       "         [ 0.6859, -0.5241,  0.2817,  ...,  0.2293, -0.5864,  0.1197],\n",
       "         [-0.1644,  0.2097, -0.4034,  ...,  1.1664, -0.3955,  0.4370]],\n",
       "\n",
       "        [[-0.1782, -0.0874,  0.5106,  ...,  0.6927,  0.0215, -1.3095],\n",
       "         [-1.1741,  1.1325,  0.0699,  ..., -1.6634,  0.5199,  0.0522],\n",
       "         [ 0.2421, -0.1489, -0.5400,  ...,  1.9069, -0.6936, -0.1559],\n",
       "         [ 0.2902, -0.7433,  0.6532,  ...,  0.6871, -0.9531, -0.1235]],\n",
       "\n",
       "        [[ 0.3663,  0.4436, -0.0897,  ..., -1.5657,  1.8553,  0.2667],\n",
       "         [-0.5762,  0.1992, -0.1589,  ...,  2.0778, -1.0215,  1.2231],\n",
       "         [-0.0198, -0.2207,  1.5419,  ...,  1.3412, -0.9325,  0.6596],\n",
       "         [ 0.6751, -1.6875, -0.6909,  ..., -0.8942,  1.0982,  0.5530]],\n",
       "\n",
       "        [[-1.2060,  1.0094,  0.7430,  ..., -1.5392,  1.3178, -0.8458],\n",
       "         [ 0.7092, -0.5124,  0.0356,  ..., -1.5251,  0.9058, -1.2159],\n",
       "         [-0.3478,  0.9345,  1.0923,  ...,  0.2006, -1.0497,  1.4871],\n",
       "         [-0.8718,  0.3543,  0.5982,  ..., -0.8765,  1.0053, -0.7657]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Forward(x, adj_norm, w):\n",
    "        # 直接使用torch.matmul进行批量矩阵乘法\n",
    "        # input: (batch_size, n_nodes, in_features) 乘以 weight: (in_features, out_features)\n",
    "        support = torch.matmul(x, w)  # (batch_size, n_nodes, out_features)\n",
    "        # 归一化邻接矩阵为 (n_nodes, n_nodes) 会自动广播到batch维度\n",
    "        output = torch.matmul(adj_norm, support)\n",
    "        return output\n",
    "\n",
    "gcn_outputs = []\n",
    "for t in range(x.size(1)):\n",
    "    x_t = x[:, t, :, :]  # (batch, nodes, feat)\n",
    "    h = Forward(x_t, A_norm, w)\n",
    "    # 展平节点特征 (batch, nodes*hidden)\n",
    "    h_flat = h.view(x.size(0), -1)\n",
    "    gcn_outputs.append(h_flat.unsqueeze(1))  # 每个时间步的输出\n",
    "\n",
    "# 构建GRU输入序列 (batch, time, features)\n",
    "gru_input = torch.cat(gcn_outputs, dim=1)\n",
    "gru_input.shape\n",
    "gru_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True, False,  True]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ..., False,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ..., False,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_input.round(decimals=6) == y.round(decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 20])\n",
      "torch.Size([10, 128, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1]), 10, tensor(2.1213))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(10, 128, 20)\n",
    "print(input[[0, 1]].shape)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "x = torch.arange(0, 10)\n",
    "y = x[1]\n",
    "y.unsqueeze_(dim=0)\n",
    "y, len(output), (x.sum() / x.shape[0]).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "loss(input, target)\n",
    "y = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y.shape[1]\n",
    "\n",
    "x = torch.tensor(2)\n",
    "print(x)\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29]]])\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24],\n",
      "        [25, 26, 27, 28, 29]])\n",
      "tensor([[[ 0,  5],\n",
      "         [ 1,  6],\n",
      "         [ 2,  7],\n",
      "         [ 3,  8],\n",
      "         [ 4,  9]],\n",
      "\n",
      "        [[10, 15],\n",
      "         [11, 16],\n",
      "         [12, 17],\n",
      "         [13, 18],\n",
      "         [14, 19]],\n",
      "\n",
      "        [[20, 25],\n",
      "         [21, 26],\n",
      "         [22, 27],\n",
      "         [23, 28],\n",
      "         [24, 29]]])\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "tensor([[10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]])\n",
      "tensor([[20, 21, 22, 23, 24],\n",
      "        [25, 26, 27, 28, 29]])\n"
     ]
    }
   ],
   "source": [
    "q = torch.arange(0, 30).reshape(3, 2, 5)\n",
    "print(q)\n",
    "print(q.reshape(-1, q.shape[-1]))\n",
    "print(q.transpose(1, 2))\n",
    "for i in q:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = \"产物浓度\"\n",
    "mic_path = 'data\\mic_result.xlsx'\n",
    "adjmatrix = pd.read_excel(mic_path, header=0, index_col=0)\n",
    "adjmatrix = adjmatrix.drop(index=label, columns=label)\n",
    "adjmatrix = np.array(adjmatrix)\n",
    "norm = np.zeros(adjmatrix.shape)\n",
    "norm[adjmatrix > 0.4] = 1\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 10]), torch.Size([4, 3, 10]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.arange(0, 30, dtype=torch.float32).reshape(3, 2, 5)\n",
    "state = torch.zeros((4, 3, 10), dtype=torch.float32)\n",
    "net = nn.GRU(5, 10, 4, batch_first=True)\n",
    "h, state = net(q, state)\n",
    "h.shape, state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 1])\n",
      "模块名称: , 类型: GCNGRU\n",
      "模块名称: gcn1, 类型: GCNCov\n",
      "模块名称: gcn1.linear, 类型: Linear\n",
      "模块名称: gcn1.dropout, 类型: Dropout\n",
      "模块名称: gcn2, 类型: GCNCov\n",
      "模块名称: gcn2.linear, 类型: Linear\n",
      "模块名称: gcn2.dropout, 类型: Dropout\n",
      "模块名称: gru, 类型: GRU\n",
      "模块名称: fc, 类型: Linear\n"
     ]
    }
   ],
   "source": [
    "def graphcov(X, adjmatrix):\n",
    "    \"\"\"图卷积\"\"\"\n",
    "    degree = adjmatrix.sum(dim=1)\n",
    "    degree_inv_sqrt = degree.pow(-0.5)\n",
    "    degree_inv_sqrt[torch.isinf(degree_inv_sqrt)] = 0\n",
    "    adjmatrix_norm = adjmatrix * degree_inv_sqrt.reshape(-1, 1)\n",
    "    adjmatrix_norm = adjmatrix_norm * degree_inv_sqrt\n",
    "    return torch.matmul(adjmatrix_norm, X)\n",
    "\n",
    "class GCNCov(nn.Module):\n",
    "    \"\"\"图卷积块\"\"\"\n",
    "    def __init__(self, in_features, out_features, adjmatrix, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('adjmatrix', adjmatrix)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = graphcov(X, self.adjmatrix)\n",
    "        return self.dropout(F.relu(self.linear(Y)))\n",
    "    \n",
    "class GCNGRU(nn.Module):\n",
    "    \"\"\"GCN+GRU\"\"\"\n",
    "    def __init__(self, in_features, varible_num, hidden_fatures, out_features, num_layers, adjmatrix, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_fatures\n",
    "        self.out_features = out_features\n",
    "        self.num_layers = num_layers\n",
    "        self.gcn1 = GCNCov(in_features, in_features, adjmatrix, dropout)\n",
    "        self.gcn2 = GCNCov(in_features, in_features, adjmatrix, dropout)\n",
    "        self.gru = nn.GRU(varible_num, hidden_fatures, num_layers, \n",
    "                          batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_fatures, out_features)\n",
    "\n",
    "    def forward(self, X, states):\n",
    "        Y = self.gcn2(self.gcn1(X))\n",
    "        Y, _ = self.gru(Y.transpose(1, 2), states)\n",
    "        Y = self.fc(Y.reshape((-1, Y.shape[-1])))\n",
    "#        Y = self.fc(Y[:, -1, :])\n",
    "        return Y\n",
    "    \n",
    "    def init_states(self, device, batch_size):\n",
    "        return torch.zeros((self.num_layers, batch_size, \n",
    "                            self.hidden_features), device=device)\n",
    "win_size = 8\n",
    "gru_hidden = 128\n",
    "gru_layers = 2\n",
    "varible_num = 14\n",
    "adjmatrix = torch.ones((varible_num, varible_num), dtype=torch.float32)\n",
    "dropout = 0.2\n",
    "device = 'cuda:0'\n",
    "\n",
    "X = torch.randn((50, varible_num, win_size), dtype=torch.float32, device=device)\n",
    "new_net = GCNGRU(win_size, varible_num, gru_hidden, 1, gru_layers, adjmatrix, dropout)\n",
    "new_net = new_net.to(device=device)\n",
    "state = new_net.init_states(device, 50)\n",
    "y = new_net(X, state)\n",
    "print(y.shape)\n",
    "for name, module in new_net.named_modules():\n",
    "    print(f\"模块名称: {name}, 类型: {type(module).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [2., 3.],\n",
      "        [4., 5.],\n",
      "        [6., 7.]]) tensor([[2., 3.],\n",
      "        [4., 5.],\n",
      "        [6., 7.],\n",
      "        [8., 9.]])\n",
      "12.776990315840429\n",
      "[(0, 0), (1, 0), (2, 1), (3, 2), (3, 3)]\n",
      "335.02376179056955\n",
      "[(0, 0), (0, 1), (1, 2), (2, 3), (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 8, dtype=torch.float32).reshape(4, 2)\n",
    "y = torch.arange(2, 10, dtype=torch.float32).reshape(4, 2)\n",
    "z = torch.rand((4, 2))\n",
    "def get_distance(data, curret_sample):\n",
    "    \"\"\"计算窗口样本的距离之和\"\"\"\n",
    "    close_fn = np.abs(curret_sample - data)\n",
    "    close_fn = np.exp(-1* close_fn)\n",
    "    close_fn = close_fn.sum() / data.shape\n",
    "    distance = 1 / (close_fn + 1e-5) -1\n",
    "    return distance.item()\n",
    "print(x, y)\n",
    "distance, path = fastdtw(x, y, dist=get_distance)\n",
    "print(distance)\n",
    "print(path)\n",
    "distance, path = fastdtw(x, z, dist=get_distance)\n",
    "print(distance)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25.5540])\n",
      "tensor([453.7448])\n"
     ]
    }
   ],
   "source": [
    "def get_distance(data, curret_sample):\n",
    "    \"\"\"计算窗口样本的距离之和\"\"\"\n",
    "    close_fn = torch.abs(curret_sample - data)\n",
    "    close_fn = torch.exp(-1* close_fn)\n",
    "    close_fn = close_fn.sum(dim=1) / data.shape[1]\n",
    "    distance = torch.sum(1 / (close_fn + 1e-5) -1, dim=0, keepdim=True)\n",
    "    return distance\n",
    "distance = get_distance(x, y)\n",
    "print(distance)\n",
    "distance = get_distance(x, z)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2, 3))\n",
    "b = np.ones((2, 3))\n",
    "c = np.array([a, b])\n",
    "c.reshape(c.shape[0], -1)\n",
    "d = torch.tensor(0.1)\n",
    "e = torch.tensor(0.2)\n",
    "torch.stack((d, e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
